# RAG with Local LLMs

## Overview

This project features a web application that answers questions about me using Retrieval-Augmented Generation (RAG) with a local LLaMA3 model. The code is adapted from the [pixegami/rag-tutorial-v2](https://github.com/pixegami/rag-tutorial-v2).

## Features

- **User Interface**: A web page for users to enter questions and receive responses in real-time.
- **Local Model**: Utilizes the LLaMA3 model locally, addional provide the model with my CV and personal statement.