# RAG with Local LLMs

## Overview

This project features a web application that answers questions about me using Retrieval-Augmented Generation (RAG) with a local LLaMA3 model. The code is adapted from the [pixegami/rag-tutorial-v2](https://github.com/pixegami/rag-tutorial-v2), special thanks to the authors for the nice tutorial on RAG.

## Features

- **User Interface**: A web page for users to enter questions and receive responses in real-time.
- **Local Model**: Utilizes the LLaMA3 model locally and is further enhanced with PDF data to provide more personalized responses.